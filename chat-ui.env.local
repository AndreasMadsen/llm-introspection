MONGODB_URL=mongodb://localhost:27017

PUBLIC_APP_NAME=LocalChat # name used as title throughout the app
PUBLIC_APP_ASSETS=chatui # used to find logos & favicons in static/$PUBLIC_APP_ASSETS
PUBLIC_APP_COLOR=fuchsia # can be any of tailwind colors: https://tailwindcss.com/docs/customizing-colors#default-color-palette

# TODO: check that there should not be a space after `[/INST]` for the prompt message.

MODELS=`[
  {
    "name": "Llama2 70B-chat",
    "description": "The Llama 2 fine-tuned generative text model optimized for dialogue use cases, using 70 billion parameters. Uses deprecated system message.",
    "websiteUrl": "https://ai.meta.com/llama/",
    "preprompt": "<<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n\n",
    "chatPromptTemplate": "{{#each messages}}{{#ifUser}}<s>[INST] {{#if @first}}{{{@root.preprompt}}}{{/if}}{{content}} [/INST]{{/ifUser}}{{#ifAssistant}} {{content}} </s>{{/ifAssistant}}{{/each}}",
    "promptExamples": [
      {
        "title": "Write an email from bullet list",
        "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
      }, {
        "title": "Code a snake game",
        "prompt": "Code a basic snake game in python, give explanations for each step."
      }, {
        "title": "Assist in a task",
        "prompt": "How do I make a delicious lemon cheesecake?"
      }
    ],
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 1000,
      "max_new_tokens": 1024,
      "stop": ["[INST]", "[/INST]", "<s>", "</s>"]
    },
    "endpoints": [{"url": "http://localhost:20002/generate_stream"}]
  }, {
    "name": "Llama2 70B-chat (no sys)",
    "description": "The Llama 2 fine-tuned generative text model optimized for dialogue use cases, using 70 billion parameters. Does not use a system message, as per the new guidelines.",
    "websiteUrl": "https://ai.meta.com/llama/",
    "chatPromptTemplate": "{{#each messages}}{{#ifUser}}<s>[INST] {{content}} [/INST]{{/ifUser}}{{#ifAssistant}} {{content}} </s>{{/ifAssistant}}{{/each}}",
    "promptExamples": [
      {
        "title": "Write an email from bullet list",
        "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
      }, {
        "title": "Code a snake game",
        "prompt": "Code a basic snake game in python, give explanations for each step."
      }, {
        "title": "Assist in a task",
        "prompt": "How do I make a delicious lemon cheesecake?"
      }
    ],
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 1000,
      "max_new_tokens": 1024,
      "stop": ["[INST]", "[/INST]", "<s>", "</s>"]
    },
    "endpoints": [{"url": "http://localhost:20002/generate_stream"}]
  }, {
    "name": "Falcon 40B-instruct",
    "description": "The Falcon-40B-Instruct modle, finetuned on a mixture of chat/instruct datasets. Uses default system message.",
    "websiteUrl": "https://huggingface.co/blog/falcon",
    "chatPromptTemplate": "{{preprompt}}{{#each messages}}{{#ifUser}}User: {{content}}\n{{/ifUser}}{{#ifAssistant}}Falcon:{{content}}\n{{/ifAssistant}}{{/each}}Falcon:",
    "preprompt": "The following is a conversation between a highly knowledgeable and intelligent AI assistant, called Falcon, and a human user, called User. In the following interactions, User and Falcon will converse in natural language, and Falcon will answer User's questions. Falcon was built to be respectful, polite and inclusive. Falcon was built by the Technology Innovation Institute in Abu Dhabi. Falcon will never decline to answer a question, and always attempts to give an answer that User would be satisfied with. It knows a lot, and always tells the truth. The conversation begins.\n",
    "promptExamples": [
      {
        "title": "Holiday in Abu Dhabi",
        "prompt": "Hey Falcon! Any recommendations for my holidays in Abu Dhabi?"
      }, {
        "title": "Everett interpretation",
        "prompt": "What's the Everett interpretation of quantum mechanics?"
      }, {
        "title": "top 10 dive sites",
        "prompt": "Give me a list of the top 10 dive sites you would recommend around the world."
      }, {
        "title": "deep-water soloing",
        "prompt": "Can you tell me more about deep-water soloing?"
      }, {
        "title": "tweet about Apache 2.0 release of Falcon LLM",
        "prompt": "Can you write a short tweet about the Apache 2.0 release of our latest AI model, Falcon LLM?"
      }
    ],
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 1000,
      "max_new_tokens": 1024,
      "stop": ["User:", "Falcon:"]
    },
    "endpoints": [{"url": "http://localhost:20001/generate_stream"}]
  }, {
    "name": "Falcon 40B-instruct (no sys)",
    "description": "The Falcon-40B-Instruct modle, finetuned on a mixture of chat/instruct datasets. Does not use a system message, similar to Llama 2 recommendations.",
    "websiteUrl": "https://huggingface.co/blog/falcon",
    "chatPromptTemplate": "{{#each messages}}{{#ifUser}}User: {{content}}\n{{/ifUser}}{{#ifAssistant}}Falcon:{{content}}\n{{/ifAssistant}}{{/each}}Falcon:",
    "promptExamples": [
      {
        "title": "Holiday in Abu Dhabi",
        "prompt": "Hey Falcon! Any recommendations for my holidays in Abu Dhabi?"
      }, {
        "title": "Everett interpretation",
        "prompt": "What's the Everett interpretation of quantum mechanics?"
      }, {
        "title": "top 10 dive sites",
        "prompt": "Give me a list of the top 10 dive sites you would recommend around the world."
      }, {
        "title": "deep-water soloing",
        "prompt": "Can you tell me more about deep-water soloing?"
      }, {
        "title": "tweet about Apache 2.0 release of Falcon LLM",
        "prompt": "Can you write a short tweet about the Apache 2.0 release of our latest AI model, Falcon LLM?"
      }
    ],
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 1000,
      "max_new_tokens": 1024,
      "stop": ["User:", "Falcon:"]
    },
    "endpoints": [{"url": "http://localhost:20001/generate_stream"}]
  }
]`
